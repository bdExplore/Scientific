{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import ifft, fft, fftfreq, fftshift, ifft2, fft2\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import sklearn\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from audio_function import plot1, plot1_f, mean_data_sep, mean_autocorr_signal, corr_t, corr_f, count_time, cos_sim, cr_arr_t, norm_max, load_mat, first_second_part, filt_freq, variation_data, t_arr_for_corr_t, df, audio_data16_4, audio_data16_3, audio_data16_2, audio_data16_1, sample_rate, audio_data49_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание массивов, используемых в обработке\n",
    "t_f_arr_1 = cr_arr_t(49)\n",
    "t_f_arr_2 = cr_arr_t(47)\n",
    "t_f_arr_3 = cr_arr_t(57)\n",
    "\n",
    "audio_data16_3_1 = audio_data16_3[t_f_arr_1[0]]\n",
    "audio_data16_3_2 = audio_data16_3[t_f_arr_2[0]]\n",
    "audio_data16_3_3 = audio_data16_3[t_f_arr_3[0]]\n",
    "\n",
    "audio_data16_2_1 = audio_data16_2[t_f_arr_1[0]]\n",
    "audio_data16_2_2 = audio_data16_2[t_f_arr_2[0]]\n",
    "audio_data16_2_3 = audio_data16_2[t_f_arr_3[0]]\n",
    "\n",
    "audio_data16_1_1 = audio_data16_1[t_f_arr_1[0]]\n",
    "audio_data16_1_2 = audio_data16_1[t_f_arr_2[0]]\n",
    "audio_data16_1_3 = audio_data16_1[t_f_arr_3[0]]\n",
    "\n",
    "audio_data16_4_1 = audio_data16_4[t_f_arr_1[0]]\n",
    "audio_data16_4_2 = audio_data16_4[t_f_arr_2[0]]\n",
    "audio_data16_4_3 = audio_data16_4[t_f_arr_3[0]]\n",
    "min_len_1 = min(len(audio_data16_3_1),len(audio_data16_2_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr_1 = corr_t(audio_data16_1_3, audio_data16_2_3, 10, 1000)\n",
    "\n",
    "t_cross1 = t_arr_for_corr_t(cross_corr_1)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(t_cross1, cross_corr_1, color='blue')\n",
    "plt.xlim(-0.01, 0.01)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление задержек с помощью кросс-корреляции\n",
    "def calculate_tdoa(signal1, signal2, fs):\n",
    "    corr = signal.correlate(signal1, signal2, mode=\"full\")\n",
    "    corr = corr_t(signal1, signal2, 30, 1000)\n",
    "    delay_samples = np.argmax(corr) - (len(signal1)/2 - 1)\n",
    "    delay_time = delay_samples / fs  # Время задержки в секундах\n",
    "    return delay_time\n",
    "\n",
    "# Разница времен прихода сигнала (TDOA)\n",
    "tdoa_12 = calculate_tdoa(audio_data16_1_3, audio_data16_2_3, sample_rate)\n",
    "tdoa_13 = calculate_tdoa(audio_data16_1_3, audio_data16_3_3, sample_rate)\n",
    "tdoa_14 = calculate_tdoa(audio_data16_1_3, audio_data16_4_3, sample_rate)\n",
    "\n",
    "print(f\"TDOA(1-2): {tdoa_12:.6f} s\")\n",
    "print(f\"TDOA(1-3): {tdoa_13:.6f} s\")\n",
    "print(f\"TDOA(1-4): {tdoa_14:.6f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
